{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRSNET 实验复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据处理：加载点云文件，每个点云文件包括点的坐标和颜色，从点云文件中加载出：体素表示、网格点到最近点的距离。注意，训练数据要使用.mat进行存储，将下面的代码块中的file_path修改为存储数据的文件地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "\n",
    "def loadmat_dir(dir_path):\n",
    "    '''\n",
    "    读取.mat文件\n",
    "    '''\n",
    "    volumes = [] # 物体的体素表示 (32, 32, 32)\n",
    "    surfaceSamples = [] # 物体的表面采样点 (3, 1000)\n",
    "    closestPoints = [] # 标准网格点的最近点，(32, 32, 32, 3)\n",
    "    \n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith('.mat'):\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            data = loadmat(file_path)\n",
    "            volumes.append(data['Volume'])\n",
    "            surfaceSamples.append(data['surfaceSamples'])\n",
    "            closestPoints.append(data['closestPoints'])\n",
    "    \n",
    "    volumes = torch.tensor(volumes).to(torch.float32)\n",
    "    surfaceSamples = torch.tensor(surfaceSamples).permute(0, 2, 1).to(torch.float32)\n",
    "    closestPoints = torch.tensor(closestPoints).to(torch.float32)\n",
    "\n",
    "    data = {\n",
    "        'Volumes': volumes,\n",
    "        'surfaceSamples': surfaceSamples,\n",
    "        'closestPoints': closestPoints\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "# # 替换为你的.mat文件路径\n",
    "# file_path = 'datasets/shapenet/train'\n",
    "\n",
    "# # 加载.mat文件\n",
    "# data = loadmat_dir(file_path)\n",
    "# print(data.keys())\n",
    "# print(data['Volumes'].shape)\n",
    "# print(data['surfaceSamples'].shape)\n",
    "# print(data['closestPoints'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 生成一个小批量，小批量数据X长度为batch_size\n",
    "# Volume.shape = (batch_size, 32, 32, 32)\n",
    "# surfaceSamples.shape = (batch_size, 1000, 3)\n",
    "# closestPoints = (batch_size, 32, 32, 32, 3)\n",
    "def data_iter_random(data, batch_size, shuffle=True):\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 对data进行shuffle\n",
    "    num_examples = len(data['Volumes'])\n",
    "    initial_indices = list(range(0, num_examples))\n",
    "    if shuffle:\n",
    "        random.shuffle(initial_indices)\n",
    "    num_batches = num_examples // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        Volume = data['Volumes'][initial_indices_per_batch]\n",
    "        surfaceSamples = data['surfaceSamples'][initial_indices_per_batch]\n",
    "        closestPoints = data['closestPoints'][initial_indices_per_batch]\n",
    "        yield Volume, surfaceSamples, closestPoints\n",
    "\n",
    "class SeqDataLoader:\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, file_path, batch_size, shuffle=True):\n",
    "        self.data_iter_fn = data_iter_random\n",
    "        self.data = loadmat_dir(file_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.data, self.batch_size, self.shuffle)\n",
    "\n",
    "# data_loader = SeqDataLoader(file_path, batch_size=1, shuffle=False)\n",
    "# for Volume, surfaceSamples, closestPoints in data_loader:\n",
    "#     print(Volume.shape)\n",
    "#     print(surfaceSamples.shape)\n",
    "#     print(surfaceSamples[0, 0])\n",
    "#     print(closestPoints.shape)\n",
    "#     print(closestPoints[0, 0, 0, 0])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 设计网络结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRS_NET(\n",
      "  (conv): Sequential(\n",
      "    (conv0): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (leaky_relu0): LeakyReLU(negative_slope=0.01)\n",
      "    (conv1): Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (leaky_relu1): LeakyReLU(negative_slope=0.01)\n",
      "    (conv2): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (leaky_relu2): LeakyReLU(negative_slope=0.01)\n",
      "    (conv3): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (leaky_relu3): LeakyReLU(negative_slope=0.01)\n",
      "    (conv4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (pool4): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (leaky_relu4): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (fnn): Sequential(\n",
      "    (fnn5_layer0): Linear(in_features=64, out_features=192, bias=True)\n",
      "    (fnn5_leaky_relu0): LeakyReLU(negative_slope=0.01)\n",
      "    (fnn5_layer1): MyLinear()\n",
      "    (fnn5_leaky_relu1): LeakyReLU(negative_slope=0.01)\n",
      "    (fnn5_layer2): MyLinear()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, n, in_features, out_features):\n",
    "        super(MyLinear, self).__init__()\n",
    "        self.n = n\n",
    "        self.weight = nn.Parameter(torch.randn(n, in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(n, out_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (b, n, in) 或者 (b, n * in)\n",
    "        # 批量矩阵乘法，n 个不同的全连接层应用到对应的 n 维度的子向量上\n",
    "        # torch.einsum 执行 (b, n, in) @ (n, in, out) -> (b, n, out)\n",
    "        x = x.view(x.size(0), self.n, -1)\n",
    "        output = torch.einsum('bni,nio->bno', x, self.weight)\n",
    "        # 加上偏置，使用广播机制，偏置的形状为 (n, out)\n",
    "        output = output + self.bias\n",
    "        return output\n",
    "    \n",
    "class PRS_NET(nn.Module):\n",
    "    # input_size: 输入体素的分辨率大小\n",
    "    # output_size: 输出的平面和四元数的个数\n",
    "    def __init__(self, intput_size=32, output_size=3):\n",
    "        super(PRS_NET, self).__init__()\n",
    "        # The CNN has five 3D convolution layers of \n",
    "        # kernel size 3, padding 1, and stride 1. \n",
    "        # After each 3D convolution, a max pooling of kernel size 2 \n",
    "        # and leaky ReLU activation are applied.\n",
    "        self.output_size = output_size\n",
    "        conv_layer_depth = 6\n",
    "        conv = nn.Sequential()\n",
    "        conv.add_module(f'conv0', nn.Conv3d(in_channels=1, out_channels=4, kernel_size=3, padding=1))\n",
    "        conv.add_module(f'pool0', nn.MaxPool3d(kernel_size=2))\n",
    "        conv.add_module(f'leaky_relu0', nn.LeakyReLU())\n",
    "        for i in range(2, conv_layer_depth):\n",
    "            conv.add_module(f'conv{i-1}', nn.Conv3d(in_channels=2**i, out_channels=2**(i+1), kernel_size=3, padding=1))\n",
    "            conv.add_module(f'pool{i-1}', nn.MaxPool3d(kernel_size=2))\n",
    "            conv.add_module(f'leaky_relu{i-1}', nn.LeakyReLU())\n",
    "        self.conv = conv\n",
    "\n",
    "        # fnn的各层大小默认为32、16、4\n",
    "        fnn_num = output_size * 2\n",
    "        fnn = nn.Sequential()\n",
    "        fnn.add_module(f'fnn{i}_layer0', nn.Linear(64, 32 * fnn_num))\n",
    "        fnn.add_module(f'fnn{i}_leaky_relu0', nn.LeakyReLU())\n",
    "        fnn.add_module(f'fnn{i}_layer1', MyLinear(fnn_num, 32, 16))\n",
    "        fnn.add_module(f'fnn{i}_leaky_relu1', nn.LeakyReLU())\n",
    "        fnn.add_module(f'fnn{i}_layer2', MyLinear(fnn_num, 16, 4))\n",
    "        self.fnn = fnn\n",
    "        self.fnn_num = fnn_num\n",
    "\n",
    "    def forward(self, volume):\n",
    "        # volume: (batch_size, 32, 32, 32)\n",
    "        # print(\"volume:\", volume.size)\n",
    "        # output: plane, quat: (batch_size, 4)\n",
    "        volume = volume.unsqueeze(1)\n",
    "        # volume: (batch_size, 1, 32, 32, 32)\n",
    "        conv_output = self.conv(volume)\n",
    "        # print(\"conv_output:\", conv_output.size)\n",
    "        # conv_output.size = (batch_size, 32, 1, 1, 1)\n",
    "        # flatten.size = (batch_size, 32)\n",
    "        flatten = conv_output.view(conv_output.size(0), -1)\n",
    "        # print(\"flatten:\", flatten.size)\n",
    "        # fnn_output.size = (output_size * 2, batch_size, 4)\n",
    "        fnn_output = self.fnn(flatten).permute(1,0,2)\n",
    "        # print(\"fnn_output:\", fnn_output.size)\n",
    "\n",
    "        planes = fnn_output[:3]\n",
    "        quats = fnn_output[3:]\n",
    "\n",
    "        # planes.shape: (output_size, batch_size, 4)\n",
    "        # quats.shape: (output_size, batch_size, 4)\n",
    "        return planes, quats\n",
    "    \n",
    "net = PRS_NET()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 设计损失函数：包括距离损失和正则化损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 体素坐标系与点云坐标系之间的转换：(0 - 32)以及(-0.5 - 0.5)\n",
    "def point2voxel(px, gridSize=32, gridBound=0.5):\n",
    "    gridMin = -gridBound + gridBound / gridSize\n",
    "    vx = (px - gridMin) * gridSize / (2 * gridBound)\n",
    "    return vx\n",
    "\n",
    "def voxel2point(x, gridSize=32, gridBound=0.5):\n",
    "    gridMin = -gridBound + gridBound / gridSize\n",
    "    return x * (2 * gridBound) / 32 + gridMin\n",
    "\n",
    "\"\"\"四元数乘法，支持批量操作\"\"\"\n",
    "def quaternion_multiply(q1, q2):\n",
    "    # q1.shape = (batch, 1, 4)\n",
    "    # q2.shape = (batch, 1000, 4)\n",
    "    w1, x1, y1, z1 = q1[..., 0], q1[..., 1], q1[..., 2], q1[..., 3]\n",
    "    w2, x2, y2, z2 = q2[..., 0], q2[..., 1], q2[..., 2], q2[..., 3]\n",
    "    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n",
    "    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n",
    "    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2\n",
    "    z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2\n",
    "    return torch.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "\"\"\"四元数共轭\"\"\"\n",
    "def quaternion_conjugate(q):\n",
    "    w, x, y, z = q[..., 0], q[..., 1], q[..., 2], q[..., 3]\n",
    "    return torch.stack([w, -1 * x, -1 * y, -1 * z], dim=-1)\n",
    "\n",
    "\"\"\"使用四元数q旋转点p，支持批量操作\"\"\"\n",
    "def rotate_point(p, q):\n",
    "    # p.shape = (batch, 1000, 3)\n",
    "    # q.shape = (batch, 1, 4)\n",
    "    p_quat = torch.cat([torch.zeros(p.shape[0], p.shape[1], 1, device=p.device), p], dim=-1)\n",
    "    q_conj = quaternion_conjugate(q)\n",
    "    p_rotated = quaternion_multiply(quaternion_multiply(q, p_quat), q_conj)\n",
    "    return p_rotated[..., 1:]  # 返回旋转后的点坐标\n",
    "\n",
    "\"\"\"计算点关于一个平面的对称点\"\"\"\n",
    "def plane_point(p, plane):\n",
    "    # p.shape = (batch, 1000, 3)\n",
    "    # plane.shape = (batch, 1, 4)\n",
    "    length = 2 * (torch.sum(p * plane[...,:3], dim=2, keepdim=True) + plane[...,3:4]) # (batch_size, 1000, 1)\n",
    "    norm2 = torch.sum(plane[..., :3] ** 2, dim=2, keepdim=True) # (batch_size, 1, 1)\n",
    "    p1 = p - length * plane[...,:3].repeat(1, length.shape[1], 1) / (norm2 + 1e-8) # (batch_size, 1000, 3)\n",
    "    return p1\n",
    "\n",
    "\"\"\"计算点到最近点的距离，输入为点云坐标单位，输出也为点云坐标单位\"\"\"\n",
    "def calculate_distance(points, closestPoints, volume, device, gridSize=32):\n",
    "    # points.shape = (batch_size, 1000, 3)\n",
    "    # closestPoints.shape = (batch_size, 32, 32, 32, 3)\n",
    "    # volume.shape = (batch_size, 32, 32, 32)\n",
    "    # print(points.shape, closestPoints.shape, volume.shape)\n",
    "    # torch.Size([1, 1000, 3]) torch.Size([1, 32, 32, 32, 3]) torch.Size([1, 32, 32, 32])\n",
    "\n",
    "    # 寻找这个点所在的网格编号\n",
    "    inds = point2voxel(points)\n",
    "    # inds.shape = (batch_size, 1000, 3)\n",
    "    inds = torch.round(torch.clamp(inds, min=0, max=gridSize-1))\n",
    "    # inds.shape = (batch_size, 1000)\n",
    "    inds = torch.matmul(inds, torch.FloatTensor([gridSize**2, gridSize, 1]).to(device)).long()\n",
    "    # v.shape = (batch_size, 32*32*32)\n",
    "    v = volume.view(-1, gridSize**3)\n",
    "    # 这里需要对距离计算一个mask，因为有些点对应的网格是有像素的，因此这时候再算距离就不准确了，因此需要将这些点的距离置为0\n",
    "    # mask.shape = (batch_size, 1000, 1)\n",
    "    mask = (1 - torch.gather(v, 1, inds)).unsqueeze(2)\n",
    "    inds = inds.unsqueeze(2).repeat(1, 1, 3)\n",
    "    # inds.shape = (batch_size, 1000, 3)\n",
    "    cps = closestPoints.reshape(closestPoints.shape[0], -1, 3) # (batch_size, 32*32*32, 3)\n",
    "    cps = torch.gather(cps, 1, inds).to(device) \n",
    "    # cps.shape = (batch_size, 1000, 3)\n",
    "    # ------------\n",
    "    return (points - cps) * mask, cps * mask\n",
    "\n",
    "\"\"\"计算对称性损失\"\"\"\n",
    "def sym_loss(planes, quats, closestPoints, surfaceSamples, volume, device):\n",
    "    # planes.shape = (output_size, batch_size, 4)\n",
    "    # quats.shape = (output_size, batch_size, 4)\n",
    "    # closestPoints.shape = (batch_size, 32, 32, 32, 3)\n",
    "    # surfaceSamples.shape = (batch_size, 1000, 3)\n",
    "    loss_planes_sym = 0\n",
    "    loss_quats_sym = 0\n",
    "    for i in range(planes.size(0)):\n",
    "        plane = planes[i].unsqueeze(1).float() # (batch_size, 1, 4)\n",
    "        quat = quats[i].unsqueeze(1).float() # (batch_size, 1, 4)\n",
    "\n",
    "        sym_Points_plane = plane_point(surfaceSamples, plane) # (batch_size, 1000, 3)\n",
    "        distance, _ = calculate_distance(sym_Points_plane, closestPoints, volume, device) # (batch_size, 1000, 3)\n",
    "        loss_planes_sym += torch.mean(torch.sum(torch.norm(distance, dim=2), dim=1))\n",
    "\n",
    "        sym_Points_quat = rotate_point(surfaceSamples, quat)\n",
    "        distance, _ = calculate_distance(sym_Points_quat, closestPoints, volume, device)\n",
    "        loss_quats_sym += torch.mean(torch.sum(torch.norm(distance, dim=2), dim=1))\n",
    "\n",
    "    return loss_planes_sym / planes.size(0), loss_quats_sym / quats.size(0)\n",
    "\n",
    "\"\"\"计算正则化损失\"\"\" \n",
    "def reg_loss(planes, quats, device):\n",
    "    # planes.shape = (output_size, batch_size, 4)\n",
    "    # quats.shape = (output_size, batch_size, 4)\n",
    "    eye = torch.eye(3).unsqueeze(0).to(device)\n",
    "    M1 = planes[..., :3].permute(1, 0, 2) # (batch_size, 3, 3)\n",
    "    # 对M的列向量做归一化\n",
    "    M1 = M1.div(torch.norm(M1, dim=2, keepdim=True) + 1e-8)\n",
    "    M1_T = M1.permute(0, 2, 1) # (batch_size, 3, output_size)\n",
    "    loss_planes_reg = (torch.matmul(M1, M1_T) - eye).pow(2).sum(2).sum(1).mean()\n",
    "    \n",
    "    M2 = quats[..., 1:4].permute(1, 0, 2) # (batch_size, output_size, 3)\n",
    "    M2 = M2.div(torch.norm(M2, dim=2, keepdim=True) + 1e-8)\n",
    "    M2_T = M2.permute(0, 2, 1) # (batch_size, 3, output_size)\n",
    "    loss_quats_reg = (torch.matmul(M2, M2_T) - eye).pow(2).sum(2).sum(1).mean()\n",
    "\n",
    "    return loss_planes_reg, loss_quats_reg\n",
    "\n",
    "# 数据中的网格点实际上是以0，0为中心，每两个网格点跨度为gridBound/gridSize的网格点\n",
    "# 这是为了和点云中的坐标表示对齐\n",
    "# 但是在就算最近点的时候，需要将坐标转换回32*32*32，用于查询closestPoints数组\n",
    "# 这段代码参考了prsnet源码\n",
    "\n",
    "# M1 = (plane1[:3], plane2.., plane3..) = (batch_size, 3, 3)\n",
    "# M2 = (quat_dir1, quat_dir2, quat_dir3) = (batch_size, 3, 3)\n",
    "# quat_dir1为四元数对应到的归一化的旋转向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.animation as animation\n",
    "import trimesh\n",
    "import cv2\n",
    "'''用于可视化结果'''\n",
    "def view_result(save_path, obj_path=None, volume=None, points=None, sym_points=None, planes=None, quats=None, gridSize=32):\n",
    "    '''\n",
    "        points(N个采样点):       (N, 3)\n",
    "        sym_points(采样点的对称点):(N, 3)\n",
    "        plane(对称平面):          (4)\n",
    "        输出三维视图的视频到name中\n",
    "    '''\n",
    "    # 创建3D图像\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 画出原始模型\n",
    "    if obj_path is not None:\n",
    "        obj_path = os.path.join(obj_path, \"model_normalized.obj\")\n",
    "        scene = trimesh.load(obj_path)\n",
    "        for _, mesh in scene.geometry.items():\n",
    "            # 提取顶点和面\n",
    "            vertices = point2voxel(mesh.vertices)\n",
    "            faces = mesh.faces\n",
    "            # 绘制三角面片\n",
    "            ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], linewidth=0.2, triangles=faces, alpha=0.7, edgecolor='gray')\n",
    "    \n",
    "    # 绘制体素\n",
    "    if volume is not None:\n",
    "        ax.voxels(volume, facecolors='cyan', edgecolors='k')\n",
    "    \n",
    "    # 画出一些点\n",
    "    if points is not None:\n",
    "        points = point2voxel(points.cpu())\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='g')\n",
    "    if sym_points is not None:\n",
    "        sym_points = point2voxel(sym_points.cpu())\n",
    "        ax.scatter(sym_points[:, 0], sym_points[:, 1], sym_points[:, 2], c='r')\n",
    "    \n",
    "    # 画出对称平面\n",
    "    if planes is not None:\n",
    "        for j, planej in enumerate(planes):\n",
    "            planej = planej.cpu().numpy()[0]\n",
    "\n",
    "            # # 定义平面和旋转轴\n",
    "            # plane_normal = np.array([1, 0, 0])  # 平面的法向量 (x, y, z)\n",
    "            # d = 5  # 平面与原点的距离\n",
    "            # quaternion = [0, 0, np.sin(np.pi/4), np.cos(np.pi/4)]  # 四元数表示的旋转 (这里是90度绕z轴旋转)\n",
    "\n",
    "            # 定义平面上的点\n",
    "            # xx, yy = np.meshgrid(range(int(voxel.shape[0]/2)-5,int(voxel.shape[0]/2+5)), range(int(voxel.shape[1]/2-5),int(voxel.shape[1]/2)+5))\n",
    "            # zz = (-planej[..., 0] * xx - planej[..., 1] * yy - planej[..., 3]) * 1. / planej[..., 2]\n",
    "            indices = np.argsort(np.abs(planej[:3]), axis=-1)\n",
    "\n",
    "            xx, yy = np.meshgrid(range(int(gridSize/2-10),int(gridSize/2+10)), range(int(gridSize/2)-10,int(gridSize/2)+10))\n",
    "            xx1 = voxel2point(xx)\n",
    "            yy1 = voxel2point(yy)\n",
    "            zz = (-planej[indices[0]] * xx1 - planej[indices[1]] * yy1 - planej[3]) * 1. / planej[indices[2]]\n",
    "            zz = point2voxel(zz)\n",
    "            # zz = np.round(np.clip(zz, a_min=0, a_max=gridSize-1))\n",
    "            xyz = np.empty(shape=(3,)+xx.shape)\n",
    "            xyz[indices[0]] = xx\n",
    "            xyz[indices[1]] = yy\n",
    "            xyz[indices[2]] = zz\n",
    "\n",
    "            # 绘制平面\n",
    "            if(j % 3 == 0):\n",
    "                ax.plot_surface(xyz[0], xyz[1], xyz[2], alpha=0.7, color='lightblue')\n",
    "            if(j % 3 == 1):\n",
    "                ax.plot_surface(xyz[0], xyz[1], xyz[2], alpha=0.7, color='lightgreen')\n",
    "            if(j % 3 == 2):\n",
    "                ax.plot_surface(xyz[0], xyz[1], xyz[2], alpha=0.7, color='lightpink')\n",
    "        \n",
    "    if quats is not None:\n",
    "        for j, quatj in enumerate(quats):\n",
    "            # 生成旋转矩阵\n",
    "            quatj = quatj.cpu().numpy()\n",
    "            rotation = R.from_quat(quatj)\n",
    "            # 旋转向量\n",
    "            start = np.array([gridSize/2, gridSize/2, gridSize/2])\n",
    "            axis = rotation.as_rotvec()[0]  # 获取旋转向量\n",
    "            # end = start + axis  # 旋转后的终点\n",
    "            # 绘制旋转轴\n",
    "            ax.quiver(start[0], start[1], start[2], axis[0], axis[1], axis[2], color='m', length=np.linalg.norm(axis)*2)\n",
    "\n",
    "\n",
    "    # 设置图像显示范围\n",
    "    ax.set_xlim(0, gridSize)\n",
    "    ax.set_ylim(0, gridSize)\n",
    "    ax.set_zlim(0, gridSize)\n",
    "\n",
    "    # 显示图像\n",
    "    def update(num):\n",
    "        ax.view_init(elev=num, azim=num)\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=np.arange(0, 360, 10), interval=100)\n",
    "    ani.save(save_path, writer='ffmpeg', fps=10)\n",
    "    plt.close(fig)\n",
    "\n",
    "# points = torch.tensor([[0.2,0.2,0.2], [0.1,0.1,0.1], [0.4,0.4,0.4]])\n",
    "# plane = torch.tensor([0,0,0,0.05])\n",
    "# sym_points = torch.tensor([[-0.2,-0.2,-0.2], [-0.1,-0.1,-0.1], [-0.4,-0.4,-0.4]])\n",
    "# generate_result(points, sym_points, plane, name='test/images/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/492 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a04e3eab45ca15dd86060f189eb133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/492 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 测试画图功能\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# 创建3D图像\n",
    "def plot_model(obj_path, gridSize=32):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 画出原始模型\n",
    "    scene = trimesh.load(os.path.join(obj_path, \"model_normalized.obj\"))\n",
    "    for name, mesh in scene.geometry.items():\n",
    "        # 提取顶点和面\n",
    "        vertices = point2voxel(mesh.vertices)\n",
    "        faces = mesh.faces\n",
    "        # 绘制三角面片\n",
    "        ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], linewidth=0.2, triangles=faces, alpha=0.7, edgecolor='gray')\n",
    "    \n",
    "    # 设置图像显示范围\n",
    "    ax.set_xlim(0, gridSize)\n",
    "    ax.set_ylim(0, gridSize)\n",
    "    ax.set_zlim(0, gridSize)\n",
    "\n",
    "    ax.view_init(elev=30, azim=30)\n",
    "\n",
    "    plt.savefig(os.path.join(obj_path, \"model_normalized.png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "base_dir = \"preprocess/shapenet/02691156/\"\n",
    "for dir_name in tqdm(sorted(os.listdir(base_dir))):\n",
    "    print(dir_name)\n",
    "    obj_path = os.path.join(base_dir, dir_name, \"models\")\n",
    "    plot_model(obj_path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000, 3]) torch.Size([1, 32, 32, 32, 3]) torch.Size([1, 32, 32, 32])\n",
      "tensor(343.3512)\n",
      "tensor([[-0.0696, -0.2409,  0.0015],\n",
      "        [-0.0696, -0.2409,  0.0015],\n",
      "        [-0.0696, -0.2409,  0.0015],\n",
      "        [-0.0696, -0.2409,  0.0015],\n",
      "        [-0.0696, -0.2409,  0.0015]])\n"
     ]
    }
   ],
   "source": [
    "test_path = 'test/test_models_2aec'\n",
    "data = loadmat_dir(test_path)\n",
    "# 测试损失函数是否正确，包括找最近点和进行对称操作\n",
    "# print(data.keys())\n",
    "# print(data['Volumes'].shape)\n",
    "# print(data['surfaceSamples'].shape)\n",
    "# print(data['closestPoints'].shape)\n",
    "points = data['surfaceSamples']\n",
    "closestPoints = data['closestPoints']\n",
    "volumes = data['Volumes']\n",
    "plane = torch.tensor([[[0,0,0.25,0.05]]])\n",
    "sym_points = plane_point(points, plane)      \n",
    "print(points.shape, closestPoints.shape, volumes.shape)\n",
    "distance, cps = calculate_distance(sym_points, closestPoints, volumes, 'cpu')\n",
    "print(torch.sum(torch.norm(distance, dim=2)))\n",
    "# print(points[0, :5])\n",
    "# print(sym_points[0, :5])\n",
    "print(closestPoints[0, 0, 0, :5])\n",
    "cps = closestPoints.reshape(closestPoints.shape[0], -1, 3)\n",
    "\n",
    "save_path = 'test/images/testsym.mp4'\n",
    "obj_path = 'test/test_models_2aec'\n",
    "# view_result(save_path, None, volumes[0], None, cps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class symLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(symLoss, self).__init__()\n",
    "        self.device = device\n",
    "    def forward(self, planes, quats, closestPoints, surfaceSamples, volume):\n",
    "        # 定义损失计算逻辑\n",
    "        # 例如，使用均方误差作为损失\n",
    "        return sym_loss(planes, quats, closestPoints, surfaceSamples, volume, self.device)\n",
    "\n",
    "class regLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(regLoss, self).__init__()\n",
    "        self.device = device    \n",
    "    def forward(self, planes, quats):\n",
    "        # 定义损失计算逻辑\n",
    "        # 例如，使用均方误差作为损失\n",
    "        return reg_loss(planes, quats, self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 设计训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练统计模块，参考自动手学深度学习库d2l'''\n",
    "# from d2l import torch as d2l\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`sec_minibatch_sgd`\"\"\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"训练模型一个迭代周期（定义见第3章）。\"\"\"\n",
    "def train_epoch(net, train_iter, sym_loss, reg_loss, updater, device, weight=25):\n",
    "    state, timer = None, Timer()\n",
    "    metric_loss_plane_sym = Accumulator(2)  # 统计训练损失之和\n",
    "    metric_loss_plane_reg = Accumulator(2)  # 统计训练准确度之和\n",
    "    metric_loss_quat_sym = Accumulator(2)  # 统计训练损失之和\n",
    "    metric_loss_quat_reg = Accumulator(2)  # 统计训练准确度之和\n",
    "\n",
    "    for Volume, surfaceSamples, closestPoints in train_iter:\n",
    "        Volume = Volume.to(device)\n",
    "        surfaceSamples = surfaceSamples.to(device)\n",
    "        closestPoints = closestPoints.to(device)\n",
    "        \n",
    "        batch_size = Volume.shape[0]\n",
    "        # 在第一次迭代或使用随机抽样时初始化state\n",
    "        updater.zero_grad()\n",
    "        # 对于ffn，我们只使用最后一个时间步计算损失\n",
    "        # y_hat.shape = (num_steps * batch_size, vocab_size)\n",
    "        planes, quats = net(Volume)\n",
    "        loss_plane_sym, loss_quat_sym = sym_loss(planes, quats, closestPoints, surfaceSamples, Volume)\n",
    "        loss_plane_reg, loss_quat_reg = reg_loss(planes, quats)\n",
    "        loss = loss_plane_sym + loss_quat_sym + (loss_plane_reg + loss_quat_reg) * weight\n",
    "        loss.backward()\n",
    "        updater.step()\n",
    "        \n",
    "        metric_loss_plane_sym.add(loss_plane_sym * batch_size, batch_size)\n",
    "        metric_loss_plane_reg.add(loss_plane_reg * batch_size, batch_size)\n",
    "        metric_loss_quat_sym.add(loss_quat_sym * batch_size, batch_size)\n",
    "        metric_loss_quat_reg.add(loss_quat_reg * batch_size, batch_size)\n",
    "\n",
    "    return metric_loss_plane_sym[0] / metric_loss_plane_sym[1],  \\\n",
    "            metric_loss_plane_reg[0] / metric_loss_plane_reg[1], \\\n",
    "            metric_loss_quat_sym[0] / metric_loss_quat_sym[1],   \\\n",
    "            metric_loss_quat_reg[0] / metric_loss_quat_reg[1],   \\\n",
    "            metric_loss_plane_sym[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import tensorboard\n",
    "from tqdm import tqdm\n",
    "# 将matplotlib中画出来的图像转成tensor，以便在tensorboard中进行显示\n",
    "def get_tensor_from_video(video_path):\n",
    "    \"\"\"\n",
    "    :param video_path: 视频文件地址\n",
    "    :return: pytorch tensor\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_list = []\n",
    "    while(cap.isOpened()):\n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        else:\n",
    "            # 注意，opencv默认读取的为BGR通道组成模式，需要转换为RGB通道模式\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames_list.append(frame)\n",
    "    cap.release()\n",
    "    result_frames = torch.as_tensor(np.stack(frames_list), dtype=torch.uint8)\n",
    "    # 注意：此时result_frames组成的维度为[视频帧数量，宽，高，通道数]\n",
    "    result_frames = result_frames.permute(0,3,2,1).unsqueeze(0)\n",
    "    return result_frames\n",
    "\n",
    "'''训练函数'''\n",
    "def train(net, train_iter, lr, num_epochs, device, weight = 25, test_file_path='test/test_models_2aec'):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    def init_weights(layer):\n",
    "        if isinstance(layer, nn.Conv3d):\n",
    "            # 使用 Kaiming 正态分布初始化\n",
    "            nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "            if layer.bias is not None:\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        elif isinstance(layer, nn.Linear):\n",
    "            # 使用 Xavier 均匀分布初始化\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.zeros_(layer.bias)\n",
    "\n",
    "    net.to(device)  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "    sym_loss = symLoss(device)\n",
    "    reg_loss = regLoss(device)\n",
    "\n",
    "    writer = tensorboard.SummaryWriter(log_dir=\"./logs\", filename_suffix='prsnet')\n",
    "    test_input = torch.rand((32, 32, 32, 32)).to(device)\n",
    "    writer.add_graph(net, test_input) \n",
    "\n",
    "    updater = torch.optim.Adam(net.parameters(), lr)\n",
    "\n",
    "    test_data = loadmat_dir(test_file_path)\n",
    "    test_Volume = test_data['Volumes'][0]\n",
    "    test_Volume = torch.tensor(test_Volume).to(torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # 训练和预测\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        loss_plane_sym, loss_plane_reg, loss_quat_sym, loss_quat_reg, speed = train_epoch(\n",
    "                                                        net, train_iter, sym_loss, reg_loss, updater, device, weight)\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        writer.add_scalars(\"sym_loss\", {'plane_loss': loss_plane_sym}, epoch)\n",
    "        writer.add_scalars(\"sym_loss\", {'quat_loss': loss_quat_sym}, epoch)\n",
    "        writer.add_scalars(\"reg_loss\", {'plane_loss': loss_plane_reg}, epoch)\n",
    "        writer.add_scalars(\"reg_loss\", {'quat_loss': loss_quat_reg}, epoch)\n",
    "        \n",
    "        if epoch % 40 == 0:\n",
    "            with torch.no_grad():\n",
    "                planes, quats = net(test_Volume)\n",
    "            save_path = \"test/images/train_\"+str(epoch)+'.mp4'\n",
    "            view_result(save_path, None, test_Volume[0], None, None, planes, quats)\n",
    "            vedio = get_tensor_from_video(save_path)\n",
    "            writer.add_video(\"Animation\", vedio, epoch) \n",
    "            \n",
    "    print(f'loss_plane_sym: {loss_plane_sym:.1f},\\n\\\n",
    "          loss_plane_reg: {loss_plane_reg:.1f}, \\n\\\n",
    "          loss_quat_sym: {loss_quat_sym:.1f}, \\n\\\n",
    "          loss_quat_reg: {loss_quat_reg:.1f}, \\n\\\n",
    "          {speed:.1f} 模型/秒 {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on:  cuda:2\n",
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "# 测试网络结构\n",
    "file_path = 'datasets/shapenet/train'\n",
    "net = PRS_NET()\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on: \", device)\n",
    "print(\"Loading data\")\n",
    "batch_size = 32\n",
    "data_loader = SeqDataLoader(file_path, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 400\n",
    "weight = 25\n",
    "train(net, data_loader, lr, num_epochs, device, weight)\n",
    "torch.save(net.state_dict(), './logs/model/model_weights_400.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir ./logs --port=6006 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 设计推理函数，给定一张图片，推理出需要的景象结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 进行测试，输入一个mat文件，输出对应的体素3D视图和对称平面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清除掉太过于重合或者置信度太低的平面和旋转向量\n",
    "def validation(planes, quats, closestPoints, surfaceSamples, volume, device, eps=4e-4):\n",
    "    valid_plane = torch.ones(3, dtype=torch.bool).to(device)\n",
    "    valid_quat = torch.ones(3, dtype=torch.bool).to(device)\n",
    "    plane_losses, quat_losses = [], []\n",
    "\n",
    "    # 排除损失值太大的对称平面或旋转轴\n",
    "    for i in range(planes.shape[0]):\n",
    "        plane_loss, quat_loss = sym_loss(planes[i].unsqueeze(0), \n",
    "                                         quats[i].unsqueeze(0), closestPoints, surfaceSamples, volume, device)\n",
    "        if plane_loss > eps:\n",
    "            valid_plane[i] = 0\n",
    "        if quat_loss > eps:\n",
    "            valid_quat[i] = 0\n",
    "        \n",
    "        plane_losses.append(plane_loss)\n",
    "        quat_losses.append(plane_loss)\n",
    "    \n",
    "    print(\"Plane_losses:\", plane_losses)\n",
    "    print(\"quat_losses:\", quat_loss)\n",
    "    \n",
    "    # 排除彼此之间靠的太近的对称平面或旋转轴\n",
    "    def test_angle(vec1, vec2):\n",
    "        angle = torch.dot(vec1, vec2) / torch.sqrt(torch.norm(vec1) * torch.norm(vec2))\n",
    "        if torch.abs(angle) > (torch.sqrt(3) / 2):\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def remove_overlap_vec(vecs, valid_vec, vec_losses):\n",
    "        for i in range(vecs.shape[0]):\n",
    "            for j in range(0, i):\n",
    "                if valid_vec[i] == 0 or valid_vec[j] == 0:\n",
    "                    continue\n",
    "                if test_angle(vecs[i], vecs[j]) == 1:\n",
    "                    if vec_losses[i] > vec_losses[j]:\n",
    "                        valid_vec[i] = 0\n",
    "                    else:\n",
    "                        valid_vec[j] = 0\n",
    "    \n",
    "    remove_overlap_vec(planes[..., :3], valid_plane, plane_losses)\n",
    "    remove_overlap_vec(quats[..., :3], valid_quat, quat_losses)\n",
    "\n",
    "    valid_planes = planes[valid_plane]\n",
    "    valid_quats = quats[valid_quat]\n",
    "\n",
    "    return valid_planes, valid_quats\n",
    "\n",
    "# 输入Volume，输出预测出来的对称平面视频到save_path\n",
    "def predict(net, obj_path, save_path, Volume, closestPoints, surfaceSamples, device):\n",
    "    '''\n",
    "        net: 网络\n",
    "        obj_path: 物体的原始网格表示\n",
    "        save_path: 保存视频的地址\n",
    "        Volume: 物体的体素表示，(1, 32, 32, 32)\n",
    "        closestPoints: 最近点，(1, 32, 32, 32, 3)\n",
    "        surfaceSamples: 物体表面的采样点，(1, 1000, 3)\n",
    "    '''\n",
    "    Volume = Volume.to(torch.float32).to(device)\n",
    "    closestPoints = closestPoints.to(device)\n",
    "    surfaceSamples = surfaceSamples.to(device)\n",
    "    # print(\"surfaceSamples.shape\", surfaceSamples.shape)\n",
    "    with torch.no_grad():\n",
    "        planes, quats = net(Volume)\n",
    "    # 由于实际计算出来的损失值太大，按照文章中的eps值，会将所有的对称平面和对称轴给删除掉\n",
    "    # valid_planes, valid_quats = validation(planes, quats, closestPoints, surfaceSamples, Volume, device)\n",
    "    sym_Points_plane = plane_point(surfaceSamples, planes[1:2])\n",
    "    distance, cps = calculate_distance(sym_Points_plane, closestPoints, Volume, device)\n",
    "    # view_result(save_path, None, Volume[0], None, cps[0], planes[1:2], None)\n",
    "    view_result(save_path, None, Volume[0], None, None, planes, None)\n",
    "    return planes, quats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "net = PRS_NET()\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load('logs/model/model_weights_400.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num: tensor(645, device='cuda:1')\n",
      "tensor(-2.9934, device='cuda:1')\n",
      "Num: tensor(731, device='cuda:1')\n",
      "tensor(-0.3752, device='cuda:1')\n",
      "Num: tensor(462, device='cuda:1')\n",
      "tensor(14.8257, device='cuda:1')\n",
      "Num: tensor(542, device='cuda:1')\n",
      "tensor(-12.1591, device='cuda:1')\n",
      "Num: tensor(385, device='cuda:1')\n",
      "tensor(5.2771, device='cuda:1')\n",
      "Num: tensor(489, device='cuda:1')\n",
      "tensor(-7.9840, device='cuda:1')\n",
      "Num: tensor(679, device='cuda:1')\n",
      "tensor(-10.0823, device='cuda:1')\n",
      "Num: tensor(245, device='cuda:1')\n",
      "tensor(0.8730, device='cuda:1')\n",
      "Num: tensor(446, device='cuda:1')\n",
      "tensor(-4.2351, device='cuda:1')\n",
      "Num: tensor(650, device='cuda:1')\n",
      "tensor(13.8890, device='cuda:1')\n",
      "Num: tensor(713, device='cuda:1')\n",
      "tensor(-9.9370, device='cuda:1')\n",
      "Num: tensor(509, device='cuda:1')\n",
      "tensor(5.0329, device='cuda:1')\n",
      "Num: tensor(416, device='cuda:1')\n",
      "tensor(-7.3138, device='cuda:1')\n",
      "Num: tensor(621, device='cuda:1')\n",
      "tensor(18.7652, device='cuda:1')\n",
      "Num: tensor(372, device='cuda:1')\n",
      "tensor(11.7815, device='cuda:1')\n",
      "Num: tensor(602, device='cuda:1')\n",
      "tensor(23.2726, device='cuda:1')\n",
      "Num: tensor(616, device='cuda:1')\n",
      "tensor(-79.5405, device='cuda:1')\n",
      "Num: tensor(385, device='cuda:1')\n",
      "tensor(-6.7719, device='cuda:1')\n",
      "Num: tensor(566, device='cuda:1')\n",
      "tensor(-14.2909, device='cuda:1')\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "obj_path = 'datasets/shapenet/test'\n",
    "data = loadmat_dir(obj_path)\n",
    "for i in range(6, 25):\n",
    "    save_path = \"test/images/predict\" + str(i) + \".mp4\"\n",
    "    predict(net, None, save_path, data['Volumes'][i:i+1], data['closestPoints'][i:i+1], data['surfaceSamples'][i:i+1], device)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
